{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "path = 'C:\\Users\\Charlie2\\Documents\\pubg stat'\n",
    "filename_sample = path + '\\\\sample_submission_V2.csv'\n",
    "filename_test = path + '\\\\test_V2.csv'\n",
    "filename_train = path + '\\\\train_V2.csv'\n",
    "#test_data = pd.read_csv(filename_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# REMEMBER to add the engineered features to the test set as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Charlie2\\\\Documents\\\\pubg stat\\\\train_V2.csv'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-177-99be09934d7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\Charlie2\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Charlie2\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Charlie2\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0mnew_rows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_currow\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnew_rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Charlie2\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    273\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[1;32m    274\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Charlie2\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m_init_dict\u001b[0;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0m_arrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_init_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Charlie2\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m   5504\u001b[0m     \u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_ensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   5505\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5506\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   5508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Charlie2\\Anaconda2\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mcreate_block_manager_from_arrays\u001b[0;34m(arrays, names, axes)\u001b[0m\n\u001b[1;32m   4307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   4308\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4309\u001b[0;31m         \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mform_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4310\u001b[0m         \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   4311\u001b[0m         \u001b[0mmgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Charlie2\\Anaconda2\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mform_blocks\u001b[0;34m(arrays, names, axes)\u001b[0m\n\u001b[1;32m   4379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   4380\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint_items\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4381\u001b[0;31m         \u001b[0mint_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_multi_blockify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint_items\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4382\u001b[0m         \u001b[0mblocks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   4383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Charlie2\\Anaconda2\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36m_multi_blockify\u001b[0;34m(tuples, dtype)\u001b[0m\n\u001b[1;32m   4448\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup_block\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   4449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4450\u001b[0;31m         \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_stack_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup_block\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   4452\u001b[0m         \u001b[0mblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Charlie2\\Anaconda2\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36m_stack_arrays\u001b[0;34m(tuples, dtype)\u001b[0m\n\u001b[1;32m   4491\u001b[0m     \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0m_shape_compat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   4492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4493\u001b[0;31m     \u001b[0mstacked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4494\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   4495\u001b[0m         \u001b[0mstacked\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_compat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(filename_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assists</th>\n",
       "      <th>boosts</th>\n",
       "      <th>DBNOs</th>\n",
       "      <th>headshotKills</th>\n",
       "      <th>heals</th>\n",
       "      <th>killPlace</th>\n",
       "      <th>killPoints</th>\n",
       "      <th>killStreaks</th>\n",
       "      <th>longestKill</th>\n",
       "      <th>matchDuration</th>\n",
       "      <th>...</th>\n",
       "      <th>winBinary</th>\n",
       "      <th>matchType_duo</th>\n",
       "      <th>matchType_duo-fpp</th>\n",
       "      <th>matchType_solo</th>\n",
       "      <th>matchType_solo-fpp</th>\n",
       "      <th>matchType_squad</th>\n",
       "      <th>matchType_squad-fpp</th>\n",
       "      <th>groupId_cat</th>\n",
       "      <th>matchId_cat</th>\n",
       "      <th>winPlacePerc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.235200</td>\n",
       "      <td>1.113600</td>\n",
       "      <td>0.649600</td>\n",
       "      <td>0.230400</td>\n",
       "      <td>1.392200</td>\n",
       "      <td>47.723600</td>\n",
       "      <td>500.811000</td>\n",
       "      <td>0.531400</td>\n",
       "      <td>21.734760</td>\n",
       "      <td>1581.059200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030200</td>\n",
       "      <td>0.072400</td>\n",
       "      <td>0.225200</td>\n",
       "      <td>0.040600</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.146400</td>\n",
       "      <td>0.390400</td>\n",
       "      <td>2496.703600</td>\n",
       "      <td>2356.696400</td>\n",
       "      <td>0.475570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.577536</td>\n",
       "      <td>1.699668</td>\n",
       "      <td>1.104293</td>\n",
       "      <td>0.579123</td>\n",
       "      <td>2.640639</td>\n",
       "      <td>27.405573</td>\n",
       "      <td>629.249887</td>\n",
       "      <td>0.700223</td>\n",
       "      <td>47.232763</td>\n",
       "      <td>252.266957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171154</td>\n",
       "      <td>0.259175</td>\n",
       "      <td>0.417756</td>\n",
       "      <td>0.197381</td>\n",
       "      <td>0.330752</td>\n",
       "      <td>0.353542</td>\n",
       "      <td>0.487889</td>\n",
       "      <td>1441.764499</td>\n",
       "      <td>1361.614868</td>\n",
       "      <td>0.307808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>972.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1370.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1248.750000</td>\n",
       "      <td>1174.750000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1441.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2496.500000</td>\n",
       "      <td>2354.500000</td>\n",
       "      <td>0.461500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>1176.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.232500</td>\n",
       "      <td>1848.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3744.250000</td>\n",
       "      <td>3537.000000</td>\n",
       "      <td>0.744700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1927.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>435.200000</td>\n",
       "      <td>2202.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4994.000000</td>\n",
       "      <td>4713.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           assists       boosts        DBNOs  headshotKills        heals  \\\n",
       "count  5000.000000  5000.000000  5000.000000    5000.000000  5000.000000   \n",
       "mean      0.235200     1.113600     0.649600       0.230400     1.392200   \n",
       "std       0.577536     1.699668     1.104293       0.579123     2.640639   \n",
       "min       0.000000     0.000000     0.000000       0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000       0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000       0.000000     0.000000   \n",
       "75%       0.000000     2.000000     1.000000       0.000000     2.000000   \n",
       "max       5.000000    15.000000    12.000000       5.000000    23.000000   \n",
       "\n",
       "         killPlace   killPoints  killStreaks  longestKill  matchDuration  \\\n",
       "count  5000.000000  5000.000000  5000.000000  5000.000000    5000.000000   \n",
       "mean     47.723600   500.811000     0.531400    21.734760    1581.059200   \n",
       "std      27.405573   629.249887     0.700223    47.232763     252.266957   \n",
       "min       1.000000     0.000000     0.000000     0.000000     972.000000   \n",
       "25%      24.000000     0.000000     0.000000     0.000000    1370.000000   \n",
       "50%      48.000000     0.000000     0.000000     0.000000    1441.000000   \n",
       "75%      71.000000  1176.000000     1.000000    20.232500    1848.000000   \n",
       "max     100.000000  1927.000000     5.000000   435.200000    2202.000000   \n",
       "\n",
       "           ...         winBinary  matchType_duo  matchType_duo-fpp  \\\n",
       "count      ...       5000.000000    5000.000000        5000.000000   \n",
       "mean       ...          0.030200       0.072400           0.225200   \n",
       "std        ...          0.171154       0.259175           0.417756   \n",
       "min        ...          0.000000       0.000000           0.000000   \n",
       "25%        ...          0.000000       0.000000           0.000000   \n",
       "50%        ...          0.000000       0.000000           0.000000   \n",
       "75%        ...          0.000000       0.000000           0.000000   \n",
       "max        ...          1.000000       1.000000           1.000000   \n",
       "\n",
       "       matchType_solo  matchType_solo-fpp  matchType_squad  \\\n",
       "count     5000.000000         5000.000000      5000.000000   \n",
       "mean         0.040600            0.125000         0.146400   \n",
       "std          0.197381            0.330752         0.353542   \n",
       "min          0.000000            0.000000         0.000000   \n",
       "25%          0.000000            0.000000         0.000000   \n",
       "50%          0.000000            0.000000         0.000000   \n",
       "75%          0.000000            0.000000         0.000000   \n",
       "max          1.000000            1.000000         1.000000   \n",
       "\n",
       "       matchType_squad-fpp  groupId_cat  matchId_cat  winPlacePerc  \n",
       "count          5000.000000  5000.000000  5000.000000   5000.000000  \n",
       "mean              0.390400  2496.703600  2356.696400      0.475570  \n",
       "std               0.487889  1441.764499  1361.614868      0.307808  \n",
       "min               0.000000     0.000000     0.000000      0.000000  \n",
       "25%               0.000000  1248.750000  1174.750000      0.200000  \n",
       "50%               0.000000  2496.500000  2354.500000      0.461500  \n",
       "75%               1.000000  3744.250000  3537.000000      0.744700  \n",
       "max               1.000000  4994.000000  4713.000000      1.000000  \n",
       "\n",
       "[8 rows x 35 columns]"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5000 entries, 967044 to 4354560\n",
      "Data columns (total 37 columns):\n",
      "assists                  5000 non-null int64\n",
      "boosts                   5000 non-null int64\n",
      "damageDealt              5000 non-null float64\n",
      "DBNOs                    5000 non-null int64\n",
      "headshotKills            5000 non-null int64\n",
      "heals                    5000 non-null int64\n",
      "killPlace                5000 non-null int64\n",
      "killPoints               5000 non-null int64\n",
      "kills                    5000 non-null int64\n",
      "killStreaks              5000 non-null int64\n",
      "longestKill              5000 non-null float64\n",
      "matchDuration            5000 non-null int64\n",
      "maxPlace                 5000 non-null int64\n",
      "numGroups                5000 non-null int64\n",
      "rankPoints               5000 non-null int64\n",
      "revives                  5000 non-null int64\n",
      "rideDistance             5000 non-null float64\n",
      "roadKills                5000 non-null int64\n",
      "swimDistance             5000 non-null float64\n",
      "teamKills                5000 non-null int64\n",
      "vehicleDestroys          5000 non-null int64\n",
      "walkDistance             5000 non-null float64\n",
      "weaponsAcquired          5000 non-null int64\n",
      "winPoints                5000 non-null int64\n",
      "playersJoined            5000 non-null int64\n",
      "killsNormalized          5000 non-null float64\n",
      "damageDealtNormalized    5000 non-null float64\n",
      "winBinary                5000 non-null int64\n",
      "matchType_duo            5000 non-null uint8\n",
      "matchType_duo-fpp        5000 non-null uint8\n",
      "matchType_solo           5000 non-null uint8\n",
      "matchType_solo-fpp       5000 non-null uint8\n",
      "matchType_squad          5000 non-null uint8\n",
      "matchType_squad-fpp      5000 non-null uint8\n",
      "groupId_cat              5000 non-null int16\n",
      "matchId_cat              5000 non-null int16\n",
      "winPlacePerc             5000 non-null float64\n",
      "dtypes: float64(8), int16(2), int64(21), uint8(6)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's start validating data by making sure every player placed at the end of the match\n",
    "# Let's check for a row with a NaN value in that column.\n",
    "train_data[train_data['winPlacePerc'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dropping that illegal match with only one player from the dataset.\n",
    "train_data.dropna(subset=['winPlacePerc'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Confirming the player is gone.\n",
    "train_data.iloc[2744604:2744604+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A game in PUBG can have up to 100 players fighting each other, but most of the times a game isn't \"full\" at 100. \n",
    "# There is no variable that gives us the number of players who joined the match, but it would be good to create one\n",
    "# to help normalize the data.\n",
    "train_data['playersJoined'] = train_data.groupby('matchId')['matchId'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = train_data.copy()\n",
    "data = data[data['playersJoined']>49]\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.countplot(data['playersJoined'])\n",
    "plt.title(\"Players Joined\",fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We need to figure out how to standardize the data, each match has a different number of players,\n",
    "# so we should normalize other features based on the amount of players.\n",
    "# Based on the \"playersJoined\" feature we can create (or change) a lot of others to normalize their values. \n",
    "# For example we can, create the \"killsNorm\" and \"damageDealtNorm\" features. \n",
    "# When there are 100 players in the game it might be easier to find and kill someone, than when there are 90 players. \n",
    "# So we can normalize the kills in a way that a kill in 100 players will score 1 (as it is) and in 90 players it will \n",
    "# score (100-90)/100 + 1 = 1.1. This is just an assumption and different scales could be used.\n",
    "\n",
    "train_data['killsNormalized'] = train_data['kills']*((100-train_data['playersJoined'])/100 + 1)\n",
    "train_data['damageDealtNormalized'] = train_data['damageDealt']*((100-train_data['playersJoined'])/100 + 1)\n",
    "train_data[['playersJoined', 'kills', 'killsNormalized', 'damageDealt', 'damageDealtNormalized']][5:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels ['kills'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-230-d39946615271>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'kills'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'damageDealt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Charlie2\\Anaconda2\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, level, inplace, errors)\u001b[0m\n\u001b[1;32m   2159\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2161\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2162\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Charlie2\\Anaconda2\\lib\\site-packages\\pandas\\core\\indexes\\base.pyc\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   3622\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3623\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[0;32m-> 3624\u001b[0;31m                                  labels[mask])\n\u001b[0m\u001b[1;32m   3625\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3626\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: labels ['kills'] not contained in axis"
     ]
    }
   ],
   "source": [
    "train_data.drop(['kills'], inplace=True, axis=1)\n",
    "train_data.drop(['damageDealt'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_dummy = train_data\n",
    "#train_dummy.groupby(['matchId']).mean()\n",
    "playerCount = train_dummy.groupby(['matchId']).count()\n",
    "playerCount = playerCount[\"Id\"].values\n",
    "n, bins, patches = plt.hist(playerCount, bins=100)\n",
    "#bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print((\"Mean player count: %d\") % np.mean(playerCount))\n",
    "print((\"Median player count: %d\") % np.ma.median(playerCount))\n",
    "print((\"Standard deviation of player count: %d\") % np.std(playerCount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scaledCount = [0]*len(playerCount)\n",
    "i = 0\n",
    "for x in playerCount:\n",
    "    scaledCount[i] = ((x-np.mean(playerCount))/np.std(playerCount))\n",
    "    i = i + 1\n",
    "plt.hist(scaledCount, bins=100)\n",
    "#Normal standardization probably isn't effective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating a column that determines if a player placed in the top 10 percent\n",
    "train_data['winBinary'] = train_data['winPlacePerc']\n",
    "def makeDummieVar(winPercent):\n",
    "    if (winPercent >= 0.9):\n",
    "        winPercent = 1\n",
    "    else:\n",
    "        winPercent = 0\n",
    "    return winPercent\n",
    "\n",
    "train_data['winBinary'] = train_data['winBinary'].apply(makeDummieVar)\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.unique(train_data['matchType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To make things less complicated, we should only look at standard matches.\n",
    "# According to the given information, the standard modes are:\n",
    "# “solo”, “duo”, “squad”, “solo-fpp”, “duo-fpp”, and “squad-fpp”.\n",
    "# (The -fpp appeneded means the game forced all players to use a \"first-person perspective\",\n",
    "# rather, than giving them the option between first-person and third-person to switch between.)\n",
    "train_data = train_data[(train_data.matchType == 'solo') | (train_data.matchType == 'duo') |\n",
    "                        (train_data.matchType == 'squad') | (train_data.matchType == 'solo-fpp') |\n",
    "                        (train_data.matchType == 'duo-fpp') | (train_data.matchType == 'squad-fpp')]\n",
    "np.unique(train_data['matchType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = 5000\n",
    "train_data = train_data.sample(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop Id column, because it probably won't be useful for our Machine Learning algorithm,\n",
    "# because the test set contains different Id's\n",
    "train_data.drop(['Id'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Need to \"One hot encode\" the matchType feature to \n",
    "# perform “binarization” of the category and include it as a feature to train the model.\n",
    "# This converts the categorical matchType variable into a form that could be provided to \n",
    "# ML algorithms to do a better job in prediction.\n",
    "\n",
    "train_data = pd.get_dummies(train_data, columns=['matchType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Taking a look at the encoding.\n",
    "matchType_encoding = train_data.filter(regex='matchType')\n",
    "matchType_encoding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# matchId's and groupId's are the other categorical variables. There are a ton of different ones so\n",
    "# one hot encoding them makes no sense, but there could still be corrleations between them, as one\n",
    "# match will have different charcteristics than the next, and the same goes for groups, so we should\n",
    "# categorize them with Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data['groupId'] = train_data['groupId'].astype('category')\n",
    "train_data['matchId'] = train_data['matchId'].astype('category')\n",
    "\n",
    "# Get category coding for groupId and matchID\n",
    "train_data['groupId_cat'] = train_data['groupId'].cat.codes\n",
    "train_data['matchId_cat'] = train_data['matchId'].cat.codes\n",
    "\n",
    "# Get rid of old columns\n",
    "train_data.drop(['groupId', 'matchId'], inplace=True, axis=1)\n",
    "\n",
    "train_data[['groupId_cat', 'matchId_cat']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# logReg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wpp = train_data['winPlacePerc']\n",
    "train_data.drop(labels=['winPlacePerc'], axis=1,inplace = True)\n",
    "train_data.insert(36, 'winPlacePerc', wpp)\n",
    "wb = train_data['winBinary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5000 entries, 967044 to 4354560\n",
      "Data columns (total 35 columns):\n",
      "assists                  5000 non-null int64\n",
      "boosts                   5000 non-null int64\n",
      "DBNOs                    5000 non-null int64\n",
      "headshotKills            5000 non-null int64\n",
      "heals                    5000 non-null int64\n",
      "killPlace                5000 non-null int64\n",
      "killPoints               5000 non-null int64\n",
      "killStreaks              5000 non-null int64\n",
      "longestKill              5000 non-null float64\n",
      "matchDuration            5000 non-null int64\n",
      "maxPlace                 5000 non-null int64\n",
      "numGroups                5000 non-null int64\n",
      "rankPoints               5000 non-null int64\n",
      "revives                  5000 non-null int64\n",
      "rideDistance             5000 non-null float64\n",
      "roadKills                5000 non-null int64\n",
      "swimDistance             5000 non-null float64\n",
      "teamKills                5000 non-null int64\n",
      "vehicleDestroys          5000 non-null int64\n",
      "walkDistance             5000 non-null float64\n",
      "weaponsAcquired          5000 non-null int64\n",
      "winPoints                5000 non-null int64\n",
      "playersJoined            5000 non-null int64\n",
      "killsNormalized          5000 non-null float64\n",
      "damageDealtNormalized    5000 non-null float64\n",
      "winBinary                5000 non-null int64\n",
      "matchType_duo            5000 non-null uint8\n",
      "matchType_duo-fpp        5000 non-null uint8\n",
      "matchType_solo           5000 non-null uint8\n",
      "matchType_solo-fpp       5000 non-null uint8\n",
      "matchType_squad          5000 non-null uint8\n",
      "matchType_squad-fpp      5000 non-null uint8\n",
      "groupId_cat              5000 non-null int16\n",
      "matchId_cat              5000 non-null int16\n",
      "winPlacePerc             5000 non-null float64\n",
      "dtypes: float64(7), int16(2), int64(20), uint8(6)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "# Take sample for debugging and exploration\n",
    "#sample = 50000\n",
    "#df_sample = train_data.sample(sample)\n",
    "df_sample = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sample = train_data\n",
    "#lr_sample = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split sample into training data and target variable\n",
    "X = df_sample.drop(['winPlacePerc', 'winBinary'], inplace=False, axis=1) #all columns except target.\n",
    "y = df_sample['winPlacePerc'] # Only target variable\n",
    "\n",
    "#Xlr = lr_sample.drop(['winPlacePerc', 'winBinary'], inplace=False, axis=1)\n",
    "#ylr = df_sample['winBinary']\n",
    "#Xlr_train, Xlr_test, ylr_train, ylr_test = train_test_split(Xlr, ylr, test_size=0.3, random_state=22,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Ranking, From Recursive Feature Elimination:\n",
      "1. matchType_squad-fpp\n",
      "2. matchType_squad\n",
      "3. boosts\n",
      "4. matchType_duo-fpp\n",
      "5. matchType_duo\n",
      "6. matchType_solo-fpp\n",
      "7. matchType_solo\n",
      "8. revives\n",
      "9. teamKills\n",
      "10. headshotKills\n",
      "11. assists\n",
      "12. weaponsAcquired\n",
      "13. roadKills\n",
      "14. killStreaks\n",
      "15. killsNormalized\n",
      "16. vehicleDestroys\n",
      "17. DBNOs\n",
      "18. heals\n",
      "19. swimDistance\n",
      "20. maxPlace\n",
      "21. numGroups\n",
      "22. playersJoined\n",
      "23. killPlace\n",
      "24. longestKill\n",
      "25. rideDistance\n",
      "26. winPoints\n",
      "27. rankPoints\n",
      "28. killPoints\n",
      "29. damageDealtNormalized\n",
      "30. walkDistance\n",
      "31. matchDuration\n",
      "32. groupId_cat\n",
      "33. matchId_cat\n"
     ]
    }
   ],
   "source": [
    "model_rfe = LogisticRegression()\n",
    "rfe = RFE(model_rfe, 1)\n",
    "X_train_int = X_train.astype('int')\n",
    "y_train_int = (y_train * 100).astype('int')\n",
    "fit = rfe.fit(X_train_int,y_train_int)\n",
    "featureNames = [0] * len(X_train.columns)\n",
    "for f in range(len(X_train.columns)):\n",
    "    featureNames[f] = list(X_train)[f]\n",
    "print(\"Feature Ranking, From Recursive Feature Elimination:\")\n",
    "rfeRanks = pd.DataFrame({'ranking':fit.ranking_,'feature':featureNames})\n",
    "rfeRanks = rfeRanks.sort_values('ranking')\n",
    "rfeRanks['feature'].reset_index(drop=True, inplace=True)\n",
    "for f in range(0, len(list(X_train))):\n",
    "    print(\"%d. %s\" % (f + 1, rfeRanks['feature'][f]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fit.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for f in range(len(fit.support_)):\n",
    "#   if fit.support_[f] == True:\n",
    "#      print featureNames[f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charlie2\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "#from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "#y_int = (y * 100).astype('int')\n",
    "\n",
    "# Create the RFE object and compute a cross-validated score.\n",
    "#svc = SVC(kernel=\"linear\")\n",
    "LRCV = LogisticRegressionCV()\n",
    "# The \"accuracy\" scoring is proportional to the number of correct\n",
    "# classifications\n",
    "rfecv = RFECV(estimator=LRCV, cv=StratifiedKFold(2), scoring='accuracy')\n",
    "rfecv_fit = rfecv.fit(X_int,y_int)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfecv.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featureNames_cv = [0] * len(rfecv_fit.ranking_)\n",
    "for f in range(len(rfecv_fit.ranking_)):\n",
    "    featureNames_cv[f] = list(X_int)[f]\n",
    "print(\"Feature Ranking, From Recursive Feature Elimination:\")\n",
    "rfeCVRanks = pd.DataFrame({'ranking':rfecv_fit.ranking_,'feature':featureNames_cv})\n",
    "rfeCVRanks = rfeCVRanks.sort_values('ranking')\n",
    "rfeCVRanks['feature'].reset_index(drop=True, inplace=True)\n",
    "for f in range(0, len(list(featureNames_cv))):\n",
    "    print(\"%d. %s\" % (f + 1, rfeCVRanks['feature'][f]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USE THE TOP FEATURES FROM RFECV IN THE RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Using the top \"#\" features from the cross-validated recursive feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Metric used for the PUBG competition (Mean Absolute Error (MAE))\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# mae is the criteron for the dataset\n",
    "rfr = RandomForestRegressor(max_depth=500,criterion='mae',\n",
    "                            max_features=None,n_estimators=75,bootstrap=True,\n",
    "                            min_samples_leaf=1,n_jobs=1,min_samples_split=2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=22,shuffle=True)\n",
    "print('X_train.shape %s, X_test.shape %s\\ny_train.shape %s, y_test.shape %s'%(X_train.shape,X_test.shape,y_train.shape,y_test.shape))\n",
    "rfr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print_score(rfr)\n",
    "res = ['mae train: ', mean_absolute_error(rfr.predict(X_train), y_train), \n",
    "           'mae val: ', mean_absolute_error(rfr.predict(X_test), y_test)]\n",
    "if hasattr(rfr, 'oob_score_'): res.append(rfr.oob_score_)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "y_pred_rfr = rfr.predict(X_test)\n",
    "# r2_score score: 1 is perfect prediction\n",
    "rfr_score=r2_score(y_pred=y_pred_rfr,y_true=y_test)\n",
    "print(\"Variance score (r2_score): %f\"%rfr_score)\n",
    "print('Model accuracy:%.2f '%(rfr_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RFpredictions = pd.DataFrame(data=y_pred_rfr)\n",
    "frames = [RFpredictions, y_test.reset_index().iloc[:,1]]\n",
    "modelTest = pd.concat(frames, axis=1)\n",
    "modelTest.columns = [\"Random Forest Predicted\", \"Actual\"]\n",
    "modelTest.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importances = rfr.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rfr.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking, from Random Forest Regressor:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. %s (%f)\" % (f + 1, featureNames[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for f in range(len(fit.ranking_)):\n",
    "    if fit.ranking_[f] == 1:\n",
    "        print featureNames[f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logReg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yp = logReg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_m = confusion_matrix(y_test, yp)\n",
    "confusion_m\n",
    "#1319+75 = 1394 correct predictions\n",
    "#33+73 = 106 incorrect predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy = (confusion_m[0,0]+confusion_m[1,1])/sum(map(sum, confusion_m))\n",
    "print(accuracy)\n",
    "#print((\"Percent Accuracy: %d\") % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lra = roc_auc_score(ylr_test, yp)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logReg.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % lra)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()\n",
    "#Logistic Regression Model significantly better at predicting a top 10% finish than random guessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_score = r2_score(y_test, yp)\n",
    "print(\"Variance score (r2_score): %f\"%lr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LRpredictions = pd.DataFrame(data=yp)\n",
    "frames = [LRpredictions, y_test.reset_index().iloc[:,1]]\n",
    "modelTest = pd.concat(frames, axis=1)\n",
    "modelTest.columns = [\"Logistic Regression Predicted\", \"Actual\"]\n",
    "modelTest.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "f,ax = plt.subplots(figsize=(15, 15))\n",
    "sns.heatmap(train_data.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = sm.Logit(ylr_train, Xlr_train) \n",
    "result = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.aic"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
